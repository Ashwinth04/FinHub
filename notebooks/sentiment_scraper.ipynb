{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebac228a-7b88-4afa-858d-f454664fc4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.164.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.9.2)\n",
      "Requirement already satisfied: tqdm in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.69.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.23.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ashwinth396/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eec1a567-6fd8-4344-96a2-326f8f5c1dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from google.genai import types\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from google import genai as gai\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, Counter\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cec834fa-bdb4-44b5-a57e-fb2a8284ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentScraper:\n",
    "\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "        if not API_KEY:\n",
    "            raise ValueError(\"GEMINI_API_KEY not found in environment variables\")\n",
    "\n",
    "        try:\n",
    "            self.client = gai.Client(api_key=API_KEY)\n",
    "            print(\"Gemini Agent initialized successfully!!\")\n",
    "        except Exception as model_error:\n",
    "            raise ValueError(f\"Failed to initialize Gemini Model: {str(model_error)}\")\n",
    "\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "        model = BertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "        self.finbert = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, truncation=True)\n",
    "        \n",
    "\n",
    "    def get_data(self, ticker, time_period):\n",
    "        prompt = f\"\"\"\n",
    "            You are a financial research assistant.\n",
    "            \n",
    "            Given a stock ticker and a time period, gather the most relevant and recent mentions of the company across multiple sources such as news articles, social media (Twitter, Reddit), financial blogs, and press releases.\n",
    "\n",
    "            Gather atleast 50 different articles\n",
    "            \n",
    "            Return only structured data in **strictly valid JSON** format with the following structure:\n",
    "            \n",
    "            {{\n",
    "              \"ticker\": \"<ticker_symbol>\",\n",
    "              \"company_name\": \"<resolved_company_name>\",\n",
    "              \"time_period\": \"<time_period>\",\n",
    "              \"mentions\": [\n",
    "                {{\n",
    "                  \"source_type\": \"<news | twitter | reddit | blog | forum | press_release>\",\n",
    "                  \"title_or_excerpt\": \"<title or post excerpt (if available)>\",\n",
    "                  \"full_text\": \"<detailed content of the article or post. If it is short, make it long>\",\n",
    "                  \"published_date\": \"<YYYY-MM-DD>\",\n",
    "                  \"source_name\": \"<source or platform>\",\n",
    "                }}\n",
    "              ]\n",
    "            }}\n",
    "\n",
    "            Source type must be one of these6 sources only:-\n",
    "            1) news\n",
    "            2) twitter\n",
    "            3) reddit\n",
    "            4) blog\n",
    "            5) forum\n",
    "            6) press_release\n",
    "            \n",
    "            Only include information that is relevant to the specified stock ticker within the given time period.  \n",
    "            If the ticker cannot be resolved to a known public company, return an empty `mentions` list but still provide the `ticker` and `time_period`.\n",
    "            Ensure that the `full_text` field contains enough content to be used as input for a sentiment analysis model. This can include the entire article or post, or a long excerpt with full context. Even if the actual content is less, process it more so as to get more context\n",
    "            \n",
    "            \n",
    "            **Do not include any commentary or text outside of the JSON.**\n",
    "            \n",
    "            Ticker: {ticker}  \n",
    "            Time Period: {time_period}\n",
    "            \n",
    "            Respond strictly with valid JSON.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Generate content using Gemini model\n",
    "            response = self.client.models.generate_content(\n",
    "                model='gemini-2.0-flash',\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    tools=[types.Tool(\n",
    "                        google_search=types.GoogleSearchRetrieval()\n",
    "                    )]\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Get the raw text from the response\n",
    "            response_text = response.text\n",
    "            \n",
    "            # Try to clean up the response to extract just the JSON part\n",
    "            try:\n",
    "                # First attempt: direct parsing\n",
    "                data = json.loads(response_text)\n",
    "            except json.JSONDecodeError:\n",
    "                # Second attempt: Try to extract JSON from potential markdown or text\n",
    "                # Look for JSON array pattern starting with [ and ending with ]\n",
    "                import re\n",
    "                json_pattern = r'\\[[\\s\\S]*\\]'\n",
    "                json_match = re.search(json_pattern, response_text)\n",
    "                \n",
    "                if json_match:\n",
    "                    try:\n",
    "                        data = json.loads(json_match.group(0))\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Failed to parse extracted JSON pattern: {str(e)}\")\n",
    "                        print(f\"Extracted pattern: {json_match.group(0)[:100]}...\")\n",
    "                        return results\n",
    "                else:\n",
    "                    print(\"No JSON array pattern found in the response\")\n",
    "                    print(f\"Raw response: {response_text[:300]}...\")\n",
    "                    return\n",
    "            \n",
    "            # Filter out incomplete entries if any\n",
    "            # valid_papers = [\n",
    "            #     paper for paper in scholar_data \n",
    "            #     if \"title\" in paper and \"summary\" in paper\n",
    "            # ]\n",
    "            \n",
    "            # Add source identifier\n",
    "            # for paper in valid_papers:\n",
    "            #     paper[\"source\"] = \"google_scholar\"\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating results for '{ticker}': {str(e)}\")\n",
    "            print(f\"Full error: {traceback.format_exc()}\")\n",
    "\n",
    "        # for i in range(len(results)):\n",
    "        #     results[i]['url'] = self.get_actual_url(results[i]['url'])\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def store_mentions_by_source(self, ticker, time_period, output_path):\n",
    "\n",
    "        mentions = []\n",
    "\n",
    "        for i in range(10):\n",
    "            data = self.get_data(ticker,time_period)\n",
    "            mentions.extend(data)\n",
    "        \n",
    "        grouped = defaultdict(list)\n",
    "        for mention in mentions:\n",
    "            source = mention.get(\"source_type\", \"unknown\").lower()\n",
    "            grouped[source].append(mention)\n",
    "    \n",
    "        output = {\n",
    "            \"ticker\": ticker,\n",
    "            \"time_period\": time_period,\n",
    "            \"collected_at\": datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"grouped_mentions\": grouped\n",
    "        }\n",
    "    \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "    def analyze_sentiment(self,filename):\n",
    "        \n",
    "        with open(filename, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        source_sentiments = defaultdict(list)\n",
    "        \n",
    "        for source, entries in data[\"grouped_mentions\"].items():\n",
    "            for entry in entries:\n",
    "                text = entry['title_or_excerpt'] + entry[\"full_text\"]\n",
    "                result = self.finbert(text[:512])[0]\n",
    "                source_sentiments[source].append(result[\"label\"].lower())\n",
    "        \n",
    "        aggregated_results = {}\n",
    "        total_counter = Counter()\n",
    "        \n",
    "        for source, sentiments in source_sentiments.items():\n",
    "            count = Counter(sentiments)\n",
    "            total = sum(count.values())\n",
    "            aggregated_results[source] = {\n",
    "                \"positive\": count[\"positive\"] / total if total else 0,\n",
    "                \"neutral\": count[\"neutral\"] / total if total else 0,\n",
    "                \"negative\": count[\"negative\"] / total if total else 0,\n",
    "                \"total_mentions\": total\n",
    "            }\n",
    "            total_counter.update(count)\n",
    "        \n",
    "        overall_total = sum(total_counter.values())\n",
    "        overall_sentiment = {\n",
    "            \"positive\": total_counter[\"positive\"] / overall_total if overall_total else 0,\n",
    "            \"neutral\": total_counter[\"neutral\"] / overall_total if overall_total else 0,\n",
    "            \"negative\": total_counter[\"negative\"] / overall_total if overall_total else 0,\n",
    "            \"total_mentions\": overall_total\n",
    "        }\n",
    "        \n",
    "        output = {\n",
    "            \"ticker\": data[\"ticker\"],\n",
    "            \"time_period\": data[\"time_period\"],\n",
    "            \"source_wise_sentiment\": aggregated_results,\n",
    "            \"overall_sentiment\": overall_sentiment\n",
    "        }\n",
    "        \n",
    "        with open(\"sentiment_results.json\", \"w\") as f:\n",
    "            json.dump(output, f, indent=2)\n",
    "\n",
    "    def fetch_and_store_historical(self, ticker: str, period: str):\n",
    "\n",
    "        period_map = {\n",
    "            \"1w\": 7,\n",
    "            \"1mo\": 30,\n",
    "            \"6mo\": 182,\n",
    "            \"1yr\": 365,\n",
    "            \"2yr\": 730,\n",
    "        }\n",
    "        \n",
    "        if period not in period_map:\n",
    "            raise ValueError(f\"Invalid period '{period}'. Choose from {list(period_map.keys())}\")\n",
    "\n",
    "        end_date = datetime.today()\n",
    "        start_date = end_date - timedelta(days=period_map[period])\n",
    "        end_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "        start_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(start=start_str, end=end_str)\n",
    "        hist.reset_index(inplace=True)\n",
    "\n",
    "        # Convert dataframe to list of dicts for JSON serialization\n",
    "        data = hist.to_dict(orient=\"records\")\n",
    "\n",
    "        filename = f\"{ticker}_{period}_historical.json\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(data, f, indent=4, default=str)\n",
    "\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "64ab1639-d192-4a2b-a0d9-a5653aca4719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Agent initialized successfully!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashwinth396/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ashwinth396/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:519: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "ss = SentimentScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf5b0654-7c4e-4fd6-b80d-82a9eb38fce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL_6mo_historical.json'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.fetch_and_store_historical(\"AAPL\",\"6mo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "40dc631d-297f-41e2-ba2b-c6216ba62802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_type': 'press_release',\n",
       "  'title_or_excerpt': 'Apple unveils powerful accessibility features coming later this year',\n",
       "  'full_text': 'Apple has announced new accessibility features coming later this year, including eye tracking, which lets users control iPad and iPhone with their eyes; Vocal Shortcuts, which allows users to create custom voice commands; and Vehicle Motion Cues, which can help reduce motion sickness for passengers [1, 5, 7, 19]. These features are designed to make Apple devices more accessible and user-friendly for people with disabilities [18].',\n",
       "  'published_date': '2025-05-13',\n",
       "  'source_name': 'Business Wire'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Chinese Retailers Offer Deep Discounts on Apple iPhones',\n",
       "  'full_text': \"Major Chinese e-commerce sites are offering discounts of up to 2,530 yuan ($351) on iPhone 16 models ahead of the '618' shopping festival [5, 8]. This move comes amid a 9% drop in shipments [8]. Apple is also experiencing increased competition from domestic vendors like Huawei and Xiaomi in China [4].\",\n",
       "  'published_date': '2025-05-14',\n",
       "  'source_name': 'Global News Select'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Apple Stock Gains on Relief from Chinese Import Tariffs',\n",
       "  'full_text': 'Apple stock is gaining ground following news of potential relief from Chinese import tariffs [5]. The United States and China have reportedly agreed to slash tariffs, marking the first sign of easing tensions between the two economic superpowers [19]. This development could benefit Apple, which has been affected by the trade war [3, 5].',\n",
       "  'published_date': '2025-05-12',\n",
       "  'source_name': 'Global News Select'},\n",
       " {'source_type': 'press_release',\n",
       "  'title_or_excerpt': 'Apple reports second quarter results',\n",
       "  'full_text': 'Apple reported its second-quarter results, with revenue rising 5% year over year to $95.4 billion [1, 5]. iPhone revenue increased by 2% to $46.8 billion [5]. The Services portfolio has emerged as a significant cash contributor [4]. Apple expects a low double-digit growth rate for its Services segment [4].',\n",
       "  'published_date': '2025-05-01',\n",
       "  'source_name': 'Business Wire'},\n",
       " {'source_type': 'blog',\n",
       "  'title_or_excerpt': \"Will Strong Services Offset Weak iPhone Sales for AAPL's Q2 Earnings?\",\n",
       "  'full_text': \"Apple's second-quarter fiscal 2025 results were expected to reflect stiff competition for iPhone in China [4]. However, strong growth in the Services business may offset this headwind [4]. Apple had more than 1 billion paid subscribers across its Services portfolio at the end of the fiscal first quarter [4].\",\n",
       "  'published_date': '2025-05-01',\n",
       "  'source_name': 'Zacks Analyst Blog'},\n",
       " {'source_type': 'reddit',\n",
       "  'title_or_excerpt': 'AAPL latest update for May 13th, 2025 (Bullish)',\n",
       "  'full_text': \"A Reddit user posted a bullish update on AAPL, congratulating those who bought the dip and held the stock [16]. There are discussions about Apple's earnings analysis, services gross margins, and growth in different regions [16]. Some users are discussing the impact of generative AI on the ad business [16].\",\n",
       "  'published_date': '2025-05-13',\n",
       "  'source_name': 'Reddit'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Smartphone Shipments Surged in March as Apple (AAPL) and Others Avoided Tariffs',\n",
       "  'full_text': 'Reports indicate that smartphone shipments surged in March as Apple and other companies avoided tariffs [9]. Apple reported a 42% growth in sell-in units in the US, contributing to a 51% rise in US smartphone inventories year-on-year [8]. Overall US smartphone shipments increased by 30% [8].',\n",
       "  'published_date': 'Unknown',\n",
       "  'source_name': 'TipRanks'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Apple (AAPL) Plans to Add Eye-Scrolling Feature to Vision Pro Headset',\n",
       "  'full_text': 'Apple is planning to add an eye-scrolling feature to its Vision Pro headset [9]. The company is also working on new accessibility features, including eye tracking for controlling iPads and iPhones [1, 5, 7, 19].',\n",
       "  'published_date': 'Unknown',\n",
       "  'source_name': 'TipRanks'},\n",
       " {'source_type': 'blog',\n",
       "  'title_or_excerpt': 'Zacks Names #1 Semiconductor Stock',\n",
       "  'full_text': 'While not directly about Apple, the blog mentions the semiconductor industry and the increasing demand for semiconductors in Artificial Intelligence, Machine Learning, and Internet of Things [13].',\n",
       "  'published_date': '2025-04-29',\n",
       "  'source_name': 'Zacks Analyst Blog'},\n",
       " {'source_type': 'twitter',\n",
       "  'title_or_excerpt': 'Apple (AAPL) Twitter Mentions Statistics 2025',\n",
       "  'full_text': 'Apple was mentioned an estimated 4,546 times in various tweets yesterday [21]. In the last 30 days, Apple has been mentioned around 7,188 times per day [21]. Apple overperforms all of its industry peers when it comes to Twitter Mentions, having more Twitter Mentions than any of its peers [21].',\n",
       "  'published_date': '2025',\n",
       "  'source_name': 'AltIndex'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Is This the End for Alphabet Stock?',\n",
       "  'full_text': \"An Apple executive stated that he expects traditional search engines to disappear and be replaced with artificial intelligence (AI)-powered search features [22]. In 2022, Alphabet paid Apple $20 billion to be the default search engine on Apple's products [22].\",\n",
       "  'published_date': '2025-05-14',\n",
       "  'source_name': 'The Motley Fool'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Apple & Nike Bounce on China Tariff News: A Closer Look',\n",
       "  'full_text': \"The prospect of reduced tariffs between the U.S. and China is positively impacting stocks like Apple and Nike [9, 19]. Any reduction in tariffs could boost Apple's earnings and improve market sentiment [5].\",\n",
       "  'published_date': 'Unknown',\n",
       "  'source_name': 'Zacks'},\n",
       " {'source_type': 'forum',\n",
       "  'title_or_excerpt': 'AAPL anyone holding buys? Feels like it struggling to go higher.',\n",
       "  'full_text': \"A user on TradingView's community forum questions whether to buy AAPL, citing its struggle to move higher [8]. Another user mentions selling calls and holding others, while another anticipates a potential breakout [8].\",\n",
       "  'published_date': 'Unknown',\n",
       "  'source_name': 'TradingView'},\n",
       " {'source_type': 'press_release',\n",
       "  'title_or_excerpt': \"Meet four of this year's Swift Student Challenge winners\",\n",
       "  'full_text': \"Apple has announced the winners of its 2025 Swift Student Challenge, recognizing young developers for their coding skills and creativity [18]. The Swift Student Challenge is part of Apple's commitment to supporting education and innovation [18].\",\n",
       "  'published_date': '2025-05-08',\n",
       "  'source_name': 'Apple Investor Relations'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Is Apple Inc. (AAPL) a buy, sell, or hold?',\n",
       "  'full_text': 'Analysts are providing mixed recommendations for Apple Inc. (AAPL), with a consensus rating of buy [9, 20]. The average rating score is Aaa, based on 78 buy ratings, 15 hold ratings, and 6 sell ratings [9].',\n",
       "  'published_date': 'Unknown',\n",
       "  'source_name': 'Seeking Alpha'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Apple Stock: Fiscal Q2 Earnings Live Blog For Investors',\n",
       "  'full_text': \"Coverage of Apple's fiscal Q2 earnings, noting cash flow from operations is up +20% YOY [15]. Operating expenses accounted for 12.9% of revenues vs. 11.7% this time last year [15]. Shares are up +3.8% this late morning in New York City, partly due to very bullish reaction to peer Facebook's earnings report last night [15].\",\n",
       "  'published_date': '2022-04-28',\n",
       "  'source_name': 'TheStreet'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'After Earnings, Is Apple Stock a Buy, a Sell, or Fairly Valued?',\n",
       "  'full_text': \"Morningstar maintains a fair value estimate of $200 for Apple, viewing shares as fairly valued [5, 25]. They project 7% compound annual revenue growth through fiscal 2029 [25]. Apple's March-quarter revenue rose 5% year over year to $95.4 billion, with iPhone revenue rising 2% to $46.8 billion [5, 25].\",\n",
       "  'published_date': '2025-05-12',\n",
       "  'source_name': 'Morningstar'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Key facts today',\n",
       "  'full_text': \"Foxconn, Apple's main manufacturer, has lowered its growth outlook from 'strong' to 'significant' due to supply chain issues and U.S. tariffs, affecting Apple's production stability [8]. Apple is offering discounts up to 2,530 yuan ($351) on iPhone 16 models via major Chinese e-commerce sites ahead of the '618' shopping festival, amid a 9% drop in shipments [5, 8].\",\n",
       "  'published_date': 'Unknown',\n",
       "  'source_name': 'TradingView'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'Wall Street loses ground, breaking a 9-day winning streak, and crude oil prices tumble.',\n",
       "  'full_text': 'While not directly about Apple, this Associated Press article provides context on the broader market trends [7].',\n",
       "  'published_date': '2025-05-04',\n",
       "  'source_name': 'Associated Press'},\n",
       " {'source_type': 'press_release',\n",
       "  'title_or_excerpt': 'Apple Arcade adds five new games in June, including UNO: Arcade Edition',\n",
       "  'full_text': 'Apple Arcade is adding five new games in June, including UNO: Arcade Edition [18]. Apple Arcade welcomes five new games and exciting updates for hit games on the service next month, with no ads or in-app purchases [18].',\n",
       "  'published_date': '2025-05-06',\n",
       "  'source_name': 'Apple Investor Relations'},\n",
       " {'source_type': 'press_release',\n",
       "  'title_or_excerpt': 'Apple introduces the 2025 Pride Collection',\n",
       "  'full_text': 'Apple has introduced the 2025 Pride Collection, celebrating the strength and beauty of LGBTQ+ communities [18]. The new Apple Watch Pride Edition Sport Band, watch face, and iPhone and iPad wallpaper celebrate the strength and beauty of LGBTQ+ communities [18].',\n",
       "  'published_date': '2025-05-05',\n",
       "  'source_name': 'Apple Investor Relations'},\n",
       " {'source_type': 'press_release',\n",
       "  'title_or_excerpt': 'Apple unveils new Mac Studio, the most powerful Mac ever, featuring M4 Max and new M3 Ultra.',\n",
       "  'full_text': 'Apple has unveiled the new Mac Studio, the most powerful Mac ever, featuring M4 Max and new M3 Ultra [1].',\n",
       "  'published_date': '2025-03-05',\n",
       "  'source_name': 'Apple Press Release'},\n",
       " {'source_type': 'news',\n",
       "  'title_or_excerpt': 'AAPL:NSQ ex-dividend date 12 May 2025 for next dividend payment May 06 2025.',\n",
       "  'full_text': 'AAPL:NSQ ex-dividend date 12 May 2025 for next dividend payment May 06 2025 [19]. On date 02 May 2025, AAPL:NSQ announced a new dividend of amount 0.26 payable on date 02 May 2025 [19].',\n",
       "  'published_date': '2025-05-06',\n",
       "  'source_name': 'FT.com'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e7fed79a-df15-49bd-8919-869dcbe4fa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be1813a8-f2db-472a-9a1d-e72a7ce07f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116452/4045263936.py:137: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"collected_at\": datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\"),\n"
     ]
    }
   ],
   "source": [
    "ss.store_mentions_by_source(\"AAPL\",\"Last 1 week\",\"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e26757eb-2174-48a9-bd96-3177da494be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.analyze_sentiment(\"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23479615-35cd-4f59-a752-34570272c546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
